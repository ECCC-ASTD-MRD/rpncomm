#!/bin/ksh93
# this script is the successor to the r.mpirun... series of scripts with expanded functionality
# (stdout/stderr post processing and "launch in background" capability)
#
# CAVEAT: this script uses typeset -Z (does not work for the bash shell)
typeset -Z4 SeqNum MemberNo MemberChild
# ===========================================================================
# start of temporary code to deal with OLD mpich2 versions needing mpdboot
#
kill_mpich2_mpd() {
  echo KILLING OLD INITIATORS IF ANY ARE FOUND
  for system in $(sort -u <${MY_NODEFILE} | xargs) 
  do
    for target in $(ssh ${system}  ps -ef | grep /bin/mpd | grep python | grep ${USER} | sed -e s'/[ ][ ]*/ /g' | cut '-d ' -f 2) 
    do
      echo KILLING process ${target} on node ${system}
      ssh ${system} kill -9 ${target}
    done 
  done
}
start_mpich2_mpd() { # start mpd daemon(s)
  mpdboot -n $( sort -u <${MY_NODEFILE} | wc -l ) -f ${MY_NODEFILE}
  echo "mpd daemon(s) started"
}
stop_mpich2_mpd() {  # stop mpd daemon(s)
  mpdallexit
  echo "mpd daemon(s) stopped"
}
#
# end of temporary code to deal with OLD mpich2 versions needing mpdboot
# ===========================================================================
#
# MPI launcher for Linux systems, openmpi or mpich2 (prefereably openmpi)
# has been tested interactively or under GridEngine
#
mpiexec_Linux() {
#  ((MpiCommWorlds>1)) && echo "ERROR: MpiCommWorlds>1 not supported yet" && return
#
# we are assuming that mpirun/mpiexec can be backgrounded.
# should this assumption be false the top line must be uncommented
#
# start of temporary code to deal with OLD mpich2 versions needing mpdboot
#
  mpirun --version 2>/dev/null 1>/dev/null || UseMpdboot=yes  # old mpich2 or no mpirun at all
  which mpdboot 2>/dev/null                || UseMpdboot=no   # mpdboot not found
  if [[ "${UseMpdboot}" == yes ]] ; then    # needed temporarily for old mpich2 versions
    echo "WARNING: using OLD version (pre 1.3) of mpich2 detected"
    kill_mpich2_mpd 
    start_mpich2_mpd
  fi
#
# end of temporary code to deal with OLD mpich2 versions needing mpdboot
#
  export ENVIRONMENT_PASSED=yes  # used to check whether mpirun transmits environment variables or not
  if [[ "${OPAL_PREFIX}" == *openmpi_1.6* ]] ; then
    OPEN_MPI_PARMS="--prefix ${OPAL_PREFIX} --stdin all --mca btl tcp,self --cpus-per-proc ${OMP_NUM_THREADS:-1}"
    unset PE_HOSTFILE
#    export OMPI_MCA_orte_default_hostfile=${MY_NODEFILE}
    [[ -f "${GECOSHEP_HOSTS_FILE}" ]] && export OMPI_MCA_orte_rsh_agent=rurun
    export OMPI_MCA_plm_rsh_disable_qrsh=1
  fi
#
  touch tmpdir/.mpi_env
  export MpiCommWorld=0
  export ChildOffset=0
  HostOffset=0
  MY_NODEFILE_ORI=${MY_NODEFILE}
  while(( MpiCommWorld<MpiCommWorlds)) ; do   # loop over MPI worlds
#
    echo ===== MPI host file for MpiCommWorld=$MpiCommWorld =====
    ((FirstHost=HostOffset+1))
    ((HostOffset=HostOffset+${PeInWorld[${MpiCommWorld}]}))
    export MY_NODEFILE=${MY_NODEFILE_ORI}.${MpiCommWorld}
    sed -n ${FirstHost},${HostOffset}p ${MY_NODEFILE_ORI} >${MY_NODEFILE}
    cat ${MY_NODEFILE}
    echo ===== MPI host file =====
#
    if [[ "${OPAL_PREFIX}" == *openmpi_1.6* ]] ; then # export environment ourselves, mpirun does not do it
       env | grep -v "'" | grep -v '"' | grep  '^[a-zA-Z0-9]' | sed -e 's/^/export /' -e 's/=/="/' -e 's/$/"/' >tmpdir/.mpi_env
    fi
#
    if ((MpiCommWorlds>1)) ; then   # more than one MPI world, launch mpirun in background
      echo ==== Backgrounding MPI world ${MpiCommWorld} with ${PeInWorld[${MpiCommWorld}]} MPI tasks ====
      cat tmpdir/.mpi_env | \
      mpirun ${OPEN_MPI_PARMS} -machinefile ${MY_NODEFILE} -n ${PeInWorld[${MpiCommWorld}]} "$@" ${ParallelScript}.${MpiCommWorld} &
    else   # only one MPI world, execute mpirun
      echo ==== Launching MPI world ${MpiCommWorld} with ${PeInWorld[${MpiCommWorld}]} MPI tasks ====
      cat tmpdir/.mpi_env | \
      mpirun ${OPEN_MPI_PARMS} -machinefile ${MY_NODEFILE} -n ${PeInWorld[${MpiCommWorld}]} "$@" ${ParallelScript}.${MpiCommWorld}
    fi
    PeAdded=${PeInWorld[${MpiCommWorld}]}
    ((ChildOffset=ChildOffset+PeAdded))
    ((MpiCommWorld=MpiCommWorld+1))
  done
  if ((MpiCommWorlds>1)) ; then
    echo "==== Waiting for ${MpiCommWorlds} MPI worlds to terminate ===="
    wait
  fi
#
  [[ "${UseMpdboot}" == yes ]] && stop_mpich2_mpd     # needed temporarily for OLD mpich2 versions that need mpdboot
}
# ===========================================================================
#
# MPI launcher for AIX, using POE under LoadLeveler, uses MP_NEWJOB for multiple MPI worlds
#
mpiexec_AIX() {
#  ((MpiCommWorlds>1)) && echo "ERROR: MpiCommWorlds>1 not supported yet" && return
  export ENVIRONMENT_PASSED=yes
  ((MpiCommWorld=0))
  if tty -s ; then  # node list only necessary in interactive case
    echo "INFO: interactive use of MPI on AIX"
    export MP_PROCS
    export MP_HOSTFILE=${MY_NODEFILE}
    grep -q $(hostname) ${HOME}/.rhosts 2>/dev/null || echo $(hostname) ${USER} >>${HOME}/.rhosts
    chmod 700 ${HOME}/.rhosts
  fi
  rm -f ${ParallelScript}.ALL
  ((MP_PROCS=0))
  while(( MpiCommWorld<MpiCommWorlds)) ; do  # build POE command file
    echo "${ParallelScript}.${MpiCommWorld}@$((MpiCommWorld+1))%${PeInWorld[${MpiCommWorld}]}%mpi:*" >>${ParallelScript}.ALL
    ((MP_PROCS=MP_PROCS+${PeInWorld[${MpiCommWorld}]}))
    ((MpiCommWorld=MpiCommWorld+1))
  done
  export MP_NEWJOB=parallel
  export ChildOffset=0   # poe takes care of adjusting MP_CHILD
  echo MP_PROCS=${MP_PROCS}
  echo "COMPLETE" >>${ParallelScript}.ALL # terminate POE command file
  echo "========== poe command file with ${MP_PROCS} tasks in ${MpiCommWorlds} MPI worlds =========="
  cat ${ParallelScript}.ALL
  poe -cmdfile ${ParallelScript}.ALL </dev/null
}
# ===========================================================================
#
# cleanup of tmpdir directory used for launch help files and listings
#
local_cleanup() {
 [[ -n ${nocleanup} ]] && return   # -nocleanup option used, return
 rm -f ${ParallelScript}* ${MP_HOSTFILE} ${MpiRunScript}* ${tmpdir}/MY_NODEFILE* ${selftest} ${tmpdir}/.mpi_env*
 rmdir ${tmpdir} || true
 [[ -d "${tmpdir}" ]] && \
 echo INFO: leftovers found in ${tmpdir} && \
 ls -al ${tmpdir} && \
 rm -rf ${tmpdir}  && \
 echo removing everything in ${tmpdir}
}
# ===========================================================================
#
# print inter task listiong separator
#
print_separator() {
  [[ -n ${nosep} ]] && return   # -nosep option used, return
  echo ===================      "$@"      ===================
}
# ===========================================================================
#
# default script for listings pos-processing
# stdout/stderr from each task listed in order
#
cat_output() {  #  cat captured stdout/stderr files into stdout with appropriate tagging
#
  Prefix3="${errp}-"
  Prefix2="${outp}${errp}-"   # prepare for stderr not split from stdout
  [[ "${spliteo}" == yes ]] && Prefix2="${outp}-"
  [[ "${tag}" == none    ]] && Prefix="" && Prefix2="" && Prefix3=""
  [[ "${tag}" == stderr  ]] && Prefix="" && Prefix2="" && Prefix3="stderr: "
  for SeqNum in $* ; do 
    ((MemberNo=SeqNum/npex+offset))
    ((MemberChild=SeqNum-SeqNum/npex*npex))
    [[ "${tag}" == full   ]] && Prefix="${MemberNo}-${MemberChild}: "
    [[ "${tag}" == member ]] && Prefix="${MemberNo}: "
    [[ "${tag}" == child  ]] && Prefix="${SeqNum}: "
    [[ -r ${SeqNum}/stdout ]] && print_separator start stdout ${MemberNo}:${MemberChild} && cat ${SeqNum}/stdout | sed -e "s/^/${Prefix2}${Prefix}/"
    [[ -r ${SeqNum}/stderr ]] && print_separator start stderr ${MemberNo}:${MemberChild} && cat ${SeqNum}/stderr | sed -e "s/^/${Prefix3}${Prefix}/"
  done
  print_separator "   stdout / stderr   "
  print_separator " end of parallel run "
}
# ===========================================================================
#
# get rid of the stdout/stderr files produced by the tasks
#
clean_output() {   #  get rid of captured stdout/stderr files into stdout
#
  [[ -n ${nocleanup} ]] && return  # -nocleanup option used, return
  for SeqNum in $* ; do 
    rm -f ${SeqNum}/std*
    rmdir ${SeqNum}
  done
}
# ===========================================================================
#
# create the MPI C executable used in the self test
# 
make_c_test() {
echo INFO: creating C test program source mpi_c_test.c
#
cat >${tmpdir}/mpi_c_test.c <<EOT
#include <unistd.h>
#include <stdlib.h>
#include <stdio.h>
#include <mpi.h>

void main(int argc, char **argv)
{
 int my_rank=-1;
 char hostname[1204];

 gethostname(hostname, 1023);
 MPI_Init(&argc,&argv);
 MPI_Comm_rank(MPI_COMM_WORLD , &my_rank);
 printf("host = %s, rank = %d \n",hostname,my_rank);
 MPI_Finalize();
}
EOT
#
echo INFO: compiling C test program mpi_c_test.c into mpi_c_test
which mpicc 2>/dev/null 1>/dev/null && mpicc -o ${tmpdir}/mpi_c_test ${tmpdir}/mpi_c_test.c
which mpcc 2>/dev/null 1>/dev/null && mpcc -o ${tmpdir}/mpi_c_test ${tmpdir}/mpi_c_test.c
echo INFO: removing C test program source mpi_c_test.c
rm ${tmpdir}/mpi_c_test.c
}
# ===========================================================================
# remap_nodes , uses node file and geometry file
# usage: remap_nodes node_list > new_reordered_node_list
#
remap_pass2() {
  ((Host=-1))
  while read Line
  do
    ((Host=Host+1))
    for i in $Line
    do
      echo $i ${HostList[$Host]} # task_number host_name
    done
  done
}
remap_nodes() {
  [[ -r "${1}" && -r "${geometry}" ]] || return 1
  ((Host=-1))
  for i in $(uniq ${1}) # build list of host names
  do
   ((Host=Host+1))
   HostList[$Host]=$i
  done
  cat ${geometry} | remap_pass2 | sort -n | cut '-d ' -f2
}
# ===========================================================================
# prepare full node list (parts of it to be used by each MPI wolrd)
# -geometry processing will only work with openmpi/linux
# in that case a node file will be expected with as many nodes as there
# are lines in the geometry file
# under AIX the remapping is expected to be performed by the LoadLeveler
# geometry keyword in the job header
# all this will have to be revisited in the future in order to support 
# heterogenous OpenMP factors (probably using the geometry)
# OMP_NUM_THREADS consistency with computed "loops" is not checked
# the script tries to keep the master node at the beginning of the node list
# this is why 'sort -u' has been replaced with 'uniq'
#
make_node_file() {   # this will be rewritten
  # if there is a geometry file, remap the node list file
  # remapping will fail if there is no node file pointed to by MY_NODEFILE
  if [[ -z ${MY_NODEFILE} ]] ; then  # no node file has been found
    if tty -s ; then   # interactive, create a node file
      ((npe_temp=npe_total))
      while (( npe_temp > 0 )) ; do ((npe_temp=npe_temp-1)) ; echo $(hostname) >> ${TMPDIR}/MY_NODEFILE ; done
    fi
  fi
#
  if [[ -f "${MY_NODEFILE}" ]] ; then  # node file exists
        rm -f $TMPDIR/MY_NODEFILE
        nhosts=$(sort -u ${MY_NODEFILE} | wc -l | sed 's/ .*//')   # number of hosts
        ((loops=(npe_total+nhosts-1)/nhosts))   # number of tasks per host
        for i in $(uniq < $MY_NODEFILE) ; do
          for j in $(seq $loops) ; do
            echo ${i} >>${TMPDIR}/MY_NODEFILE   # one entry per task
          done
        done
  fi
#
  if [[ -f "${PARALLEL_NODEFILE}" ]] ; then  # PARALLEL_NODEFILE used, override computed node list
    cp ${PARALLEL_NODEFILE} $TMPDIR/MY_NODEFILE
  fi
#
  if [[ -f "${geometry}" && -z "${PARALLEL_NODEFILE}" ]] ; then   # task geometry and no overrride of node list
    mv $TMPDIR/MY_NODEFILE $TMPDIR/MY_NODEFILE.old
    remap_nodes $TMPDIR/MY_NODEFILE.old >$TMPDIR/MY_NODEFILE
    rm $TMPDIR/MY_NODEFILE.old
  fi
#
  export MY_NODEFILE=$TMPDIR/MY_NODEFILE
}
# ===========================================================================
# wait_for creation|rm timeout directory file_names
# wait for file creation / removal with timeout (in seconds)
#
wait_for() {
  action=${1}
  time_out=${2}
  dir=${3}
  shift ; shift; shift
  for file in $* ; do
    while ((time_out>=0)); do
      [[ -f ${dir}/${file} ]]   && [[ ${action} == creation ]] && break   # creation mode and file found
      [[ ! -f ${dir}/${file} ]] && [[ ${action} != creation ]] && break   # absence mode and file not found
      ((time_out=time_out-1))      # timeout decremented only if action failed
      sleep 1
    done
    ((time_out<=0)) && return 1        # timeout expired, failure
  done
  return 0                          # timeout not expired, success
}
# ===========================================================================
echo version avec /bin/ksh93
eval `cclargs_lite $0 \
    -tmpdir "$(pwd -P)/tmpdir" "" "[temporary directory visible by all processes]" \
    -pgm "Invalid_Command.EXE" "" "[]" \
    -args "" "" "[arguments to the command]" \
    -inorder "" "yes" "[list out/err of members in process order]" \
    -processorder "" "yes" "[list out/err of members in order]" \
    -spliteo "no" "yes" "[split stderr from stdout]" \
    -npex "${BATCH_MPI_CPUS:-1}" "" "[member size, total number of cpus if 1 member]" \
    -npey "1" "" "[number of members]" \
    -nompi "run_with_mpi" "run_in_background" "[]" \
    -instances "" "" "[instance name for member or list of instances for master]" \
    -mpiargs "" "" "[]" \
    -instancedir "" "${PARALLEL_INSTANCES}" "[directory containing instance names]" \
    -geometry "" "" "[]" \
    -timeout "60" "60" "[timeout for multiple instances]" \
    -debug "" "part" "[]" \
    -nocleanup "" "nocleanup" "[]" \
    -tag "child" "full" "[full/child/member/stderr/none]" \
    -outp "o" "O" "[stdout prefix in listings]" \
    -errp "e" "E" "[stderr prefix in listings]" \
    -nosep "" "yes" "[deactivate separator between members]" \
    -preexec "" "" "[prefix program execution with this (time/gdb/...)]" \
    -packoutput "cat_output" "echo" "[]" \
    -worlds "0" "0" "[size of MPI worlds, 0=all processors available]" \
    -offset "0" "1" "[numbering of members from this value]" \
    -selftest "" "selftest.$$" "[quick selftest]" \
    ++ $*`
#
# number of MPI tasks
#
(( npe_total=npex*npey ))
#
# do we have co-running instances ?
#
if [[ -d "${instancedir}" ]] ; then     # we have multiples instances
  slaves=$(echo ${instances} | wc -w)   # if 1 it is a slave, if >1 it is the master
  if ((slaves>1)) ; then  # the master
    wait_for creation ${timeout} ${instancedir} ${instances}   # wait for all slaves to submit their resource needs
#
#   build compound launch parameters using ${instancedir}/${instances} files
#
    for i in ${instances} ; do
       touch ${instancedir}/${i}.ACK                           # acknowledge reception of slave task requirements
    done
#
#   execute MPI tasks on behalf of slaves
#
#   ${0} -tmpdir ${tmpdir} ...........
    for i in ${instances} ; do
       rm ${instancedir}/${i}.ACK                           # acknowledge end of all slave tasks
    done
    exit                                                    # job done
  else                    # a slave
    echo "$(pwd) ${npe_total} ${pgm}" >${instancedir}/${instances}.tmp || exit 1
    mv ${instancedir}/${instances}.tmp ${instancedir}/${instances}  || exit 1
    wait_for creation ${timeout} ${instancedir} ${instances}.ACK   # wait for master to acknowledge resources
    wait_for deletion 2000000000 ${instancedir} ${instances}.ACK   # wait for master to signal done (infinite timeout)
    rm ${instancedir}/${instances}
  fi
fi
#
# number of MPI worlds
#
[[ "${worlds}" == 0 ]] && ((worlds=npe_total))
((MpiCommWorlds=0))
for i in ${worlds}
do
  PeInWorld[${MpiCommWorlds}]=${i}
  ((MpiCommWorlds=MpiCommWorlds+1))  # number of MPI comm worlds
done
#
# MY_NODEFILE now contains the node list if one was specified before
#
MY_NODEFILE=${PARALLEL_NODEFILE:-${GECOSHEP_HOSTS_FILE:-${PBS_NODEFILE}}}
#
[[ -n ${inorder} ]] && processorder="yes"
# process -args @file
[[ "${args}" == @* ]] && args2=${args#@} && [[ -f ${args2} ]] && args="$(xargs <${args2})"
# args variable now contains all programs
#
# -pgm @file 
# up to 5 items per line (same syntax as -pgm)
# [directory] executable first_pe increment last_pe|@
# [directory] executable first_pe increment
# [directory] executable +number_of_pes
#
# -pgm syntax  (@ for last_pe means number of pes - 1)
# -pgm [directory] executable first_pe increment last_pe|@  (repeated)
# -pgm [directory] executable +number_of_pes (repeated)
#
# process -pgm @file
[[ "${pgm}" == @* ]] && pgm2=${pgm#@} && [[ -f ${pgm2} ]] && pgm="$(xargs <${pgm2})"
# pgm variable now contains all taht is needed
#
[[ "${debug}" == full ]] && set -x
# reset TMPDIR to make sure it is visible to all MPI tasks
mkdir -p ${tmpdir}
export TMPDIR=${tmpdir}
#
# create script anc C executable used in self test if needed
#
if [[ -n ${selftest} ]] ; then
  selftest="${tmpdir}/${selftest}"
  pgm="${selftest}"
  cat <<EOT >${selftest}
#!/bin/ksh93
echo "NODE FILE='\${MY_NODEFILE}' arguments:'\$@'"
echo "\$(hostname)(\${MP_CHILD}): RP_Child=\${RP_Child}, RP_Member=\${RP_Member}, RP_MemberChild=\${RP_MemberChild}, MP_SeqNum=\${MP_SeqNum}, RP_CommWorld=\${RP_CommWorld}"
set -x
[[ -x ${tmpdir}/mpi_c_test ]] && ${tmpdir}/mpi_c_test
rm -f ${tmpdir}/mpi_c_test
sleep \${1:-5}
EOT
 chmod 755 ${selftest}
 [[ ${nompi} == run_with_mpi ]] && make_c_test  # create C program and compile it only in MPI case
fi
#
# primary and secondary launching scripts
#
export MpiRunScript=${tmpdir}/MpiRunScript_$$
export ParallelScript=${tmpdir}/ParallelScript_$$
touch ${ParallelScript}.0
[[ ! -r ${ParallelScript}.0 ]] && echo "ERROR: ${tmpdir} not a writable directory" 1>&2 && exit 1
#
# stdout and stderr redirection
#
export RedirectStdout="1>${tmpdir}/\${MP_SeqNum}/stdout"   # will be expanded at run time in ParallelScript
export RedirectStderr="2>${tmpdir}/\${MP_SeqNum}/stderr"   # will be expanded at run time in ParallelScript
[[ "${spliteo}" == no ]] && RedirectStderr="2>&1"
[[ -z ${processorder} ]] && RedirectStderr="" && RedirectStdout=""
#
# communication variables for RPN_COMM toolkit
#
export RPN_COMM_DOM=""
export RPN_COMM_DIRS="' '"
set -- $pgm ${MPIRUN_MPMD_PGM} @@
#
if [[ "$2" != "" ]] ; then # complex sequence, SPMD or MPMD, (automatic multiple MPI worlds not implemented yet)
  ((ErRoR=0))
  ((NDomains=0))
  ((Next=0))
  ((MpiCommWorld=0))
  ((npe_total=PeInWorld[${MpiCommWorld}]))
  ((MaxPe=0))
  ((Instances=0))
#  for i in $(seq 0 1 ${npe_total_m1}) ; do ProGrams[$i]="NoNe" ; Directories[$i]="." ; done
  unset ProGrams Directories
#
  while [[ -n "${1}" ]]
  do
    ((npe_total=PeInWorld[${MpiCommWorld}]))
    ((NDomains=NDomains+1))
    if [[ -d "$1" ]] ; then Directory="$1" ; shift ; else Directory="." ; fi
    Program="$1" ; shift ; echo Program=$Program
    if [[ !  -x "$Program" ]] ; then echo program $Program does not exist or is not executable ; ((ErRoR=ErRoR+1)) ; fi
    temp=${1} 
    if [[ $temp = +* ]] ; then
       temp=${temp#+}
       ((First=Next))
       ((Increment=1))
       ((Last=First+temp-1))
       ((Next=Last+1))
       shift
    else
      ((First=${1}))
      ((Increment=${2}))
      Last=${3}
      if ((Last==0)) ; then ((Last=npe_total_m-1)) ; fi
      shift ; shift ; shift
    fi
    export RPN_COMM_DOM="$RPN_COMM_DOM,${First},${Increment},${Last}"
    export RPN_COMM_DIRS="$RPN_COMM_DIRS,'${Directory}'"
    for i in $(seq ${First} ${Increment} ${Last} )
    do
      ((Instances=Instances+1))
      if [[ -n "${ProGrams[$i]}" ]] ; then
        echo ERROR: duplicate program assignment "${ProGrams[$i]}" vs "$Program" in slot $i
        ((ErRoR=ErRoR+1))
      else
        ProGrams[$i]="$Program"
        Directories[$i]=$Directory
        ((i>MaxPe)) && ((MaxPe=i))
      fi
    done
    if [[ "$1" == "@@" ]] ; then  #  wrap up a world
      shift
      WorldSize[${MpiCommWorld}]=${Instances}
#     make sure that MaxPe <= npe_total (no overflow) and Instances == MaxPe (no holes)
      rm -f ${MpirunScript}.${MpiCommWorld}
      for i in  $(seq 0 1 $((npe_total-1))) ; do
        echo "export RPN_COMM_DOM='$RPN_COMM_DOM'" >${MpiRunScript}.${MpiCommWorld}
        echo "export RPN_COMM_DIRS='$RPN_COMM_DIRS'" >${MpiRunScript}.${MpiCommWorld}
        echo "if [[ \"\${MP_CHILD}\" == \"$i\" ]] ; then ${preexec} ${ProGrams[$i]} ${args} ; fi" >>${MpiRunScript}.${MpiCommWorld}
      done
      [[ -n "${1}" ]] && ((MpiCommWorld=MpiCommWorld+1))   # do not bump worlds counter if nothing after @@
      unset RPN_COMM_DOM RPN_COMM_DIRS                     # reset world related variables nd counters
      ((NDomains=0))
      ((Next=0))
      ((MaxPe=0))
      ((Instances=0))
    fi
  done # while [[ "$1" != "" ]]
#
  export RPN_COMM_DOM="${NDomains}${RPN_COMM_DOM}"
  rm -f ${MpirunScript}.${MpiCommWorld}
  for i in  $(seq 0 1 $((npe_total-1)))
  do
    if [[ !  -x "${ProGrams[$i]}" ]] ; then
      if [[ "${ProGrams[$i]}" = NoNe ]] ; then
        echo ERROR: no program specified for child $i
      else
        echo ${ProGrams[$i]} does not exist or is not executable "(child $i)"
      fi
      ((ErRoR=ErRoR+1))
    else
      echo "if [[ \"\${MP_CHILD}\" = \"$i\" ]] ; then ${preexec} ${ProGrams[$i]} ${args} ; fi" >>${MpiRunScript}.${MpiCommWorld}
    fi
  done
  if [[ "$ErRoR" != "0" ]] ; then echo "$ErRoR ERROR(S) detected" ; local_cleanup ; exit 1 ; fi
else # simple SPMD case, one or more MPI worlds
#
  if [[ ! -x $pgm ]] ; then
    echo $pgm does not exist or is not executable
    exit 1
  fi
  MpiCommWorld=0
  while ((MpiCommWorld<MpiCommWorlds)) # same executable for all worlds
  do
    echo ${preexec} $pgm $args >${MpiRunScript}.${MpiCommWorld}   # MpiCommWorld is 0 in this case
    ((MpiCommWorld=MpiCommWorld+1))
  done
#
fi # complex sequence, possibly MPMD
#
# prepare primary launch scripts (one per world)
#
MpiCommWorld=0
while ((MpiCommWorld<MpiCommWorlds))
do
#
  cat <<EOT >${ParallelScript}.${MpiCommWorld}
#!/bin/ksh93
[[ -n "${debug}" ]] && set -x
#
export MP_CHILD=\${MP_CHILD:-\${PMI_RANK:-\${OMPI_COMM_WORLD_RANK}}}  # poe/mpich2/openmpi
if [[ -z \${ENVIRONMENT_PASSED} ]] ; then
  cat >${tmpdir}/.mpi_env_\$\$_\$(hostname)
  . ${tmpdir}/.mpi_env_\$\$_\$(hostname)
fi
typeset -Z4 MP_SeqNum    # NOT VALID FOR bash, ksh family only
((MP_CHILD=MP_CHILD+ChildOffset))   # need to add ChildOffset for this MPI world to MP_CHILD (always 0 for poe)
export RP_CommWorld=${MpiCommWorld}
export MP_SeqNum="\$((MP_CHILD))"
export RP_Child="\$((MP_CHILD))"
export RP_Member=\$((MP_CHILD/${npex}+${offset}))
export RP_MemberChild=\$((MP_CHILD-MP_CHILD/${npex}*${npex}))
#env | sort >${tmpdir}/.mpi_env_\$\$_\$(hostname)
#
. ${MpiRunScript}.${MpiCommWorld}  ${RedirectStdout} ${RedirectStderr}
EOT
#
  chmod 755 ${ParallelScript}.${MpiCommWorld}
  ((MpiCommWorld=MpiCommWorld+1))
done
#
# we are now almost ready to launch
#
echo "RPN_COMM_DOM=$RPN_COMM_DOM"
echo "RPN_COMM_DIRS=$RPN_COMM_DIRS"
#
make_node_file
#########################################################################################################
#rm -f $TMPDIR/MY_NODEFILE
#[[ -f "${GECOSHEP_HOSTS_FILE}" ]] && MY_NODEFILE=${GECOSHEP_HOSTS_FILE}
#if [[ -n ${MY_NODEFILE} ]] ; then  # node file supplied via MY_NODEFILE or GECOSHEP_HOSTS_FILE
#  nhosts=$(sort -u ${MY_NODEFILE} | wc -l | sed 's/ .*//')
#  echo 
#  ((loops=(npe_total+nhosts-1)/nhosts))  # we assume an equal number of MPI tasks per node
#  for i in `sort -u < $MY_NODEFILE`
#  do
#    for j in $(seq $loops)
#    do
#      echo ${i} >>${TMPDIR}/MY_NODEFILE
#    done
#  done
#else  # no node file supplied via MY_NODEFILE or GECOSHEP_HOSTS_FILE environment variable
#  ((npe_temp=npe_total))
#  while (( npe_temp > 0 )) ; do ((npe_temp=npe_temp-1)) ; echo $(hostname) >> ${TMPDIR}/MY_NODEFILE ; done
#fi
#############################################################################################################
#export MY_NODEFILE=$TMPDIR/MY_NODEFILE
# create stdout/stderr directories if necessary
if [[ -n ${processorder} ]] ; then
  for SeqNum in $(seq 0 1 $((npe_total-1)))    #  a arranger pour le cal MPMD ====================================
  do 
    mkdir ${tmpdir}/${SeqNum}
  done
  echo "=============================================="
  echo "temporary listings for all members in ${tmpdir}"
  echo "=============================================="
fi
#
if [[ ${nompi} == run_with_mpi ]] ; then  # MPI launch (linux or AIX supported)
#
  echo "${MPI_EXEC:-mpiexec.$(uname -s)} ${mpiargs}"
  ${MPI_EXEC:-mpiexec_$(uname -s)} ${mpiargs}
#
else   # background launch (it is assumed that there is only one world)
#
  ((MP_CHILD=0)) # MP_CHILD used to indicate logical child number (like MPI case)
  export MP_CHILD
  while ((MP_CHILD<npe_total))
  do
    ${ParallelScript}.0 &    # world no 0
    ((MP_CHILD=MP_CHILD+1))
  done
  echo waiting for ${MP_CHILD} background tasks to terminate
  wait
#
fi
#
# post process/order listings if required
#
if [[ -n ${packoutput} && -n ${processorder} ]] ; then
  ( cd ${tmpdir} ; ${packoutput} [0-9]*[0-9] ; clean_output [0-9]*[0-9] )
fi
#
local_cleanup || true
